{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: How can a traditional - non neural network approach be used to classify celestial objects (Stars, Galaxies, and Quasars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will explain how a decision tree can be used to classify different objects within a dataset. The dataset being used is the SDSS DR14 obtained from Kaggle: https://www.kaggle.com/datasets/lucidlenn/sloan-digital-sky-survey/data.\n",
    "\n",
    "In this dataset, there are 18 columns that are used to describe the Stars, Galaxies, and Quasars observed by the SDSS telescope. However we don't necessarily need all 18 of these parameters. Columns: \"objid\", \"run\", \"rerun\", \"camcol\", \"field\", \"specobjid\", \"plate\", \"mjd\", and \"fiberid\", are all values related to the telescope and thus are not relevant. Columns: \"ra\", \"dec\", \"u\", \"g\", \"r\", \"i\", \"z\", and \"redshift\" are all values related to the objects themselves. The \"class\" column contains which group the objects fall into, this will be used to in testing to see how accuracte the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does a Decision Tree work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are flow charts that are often used for classification or regression tasks. It works by splitting data into subsets based on the answer to a question. For example in this dataset, you could split the data based on the question \"is the brightness above a certain value?\" This would then split the data into two subsets, one with brightnesses greater than the chosen value, and one with brightnesses less than the chosen value.\n",
    "\n",
    "This is repeated with different questions and eventually forms a tree structure with each splitting point forming a \"node\". It would end up looking something like this:\n",
    "\n",
    "            Is brightness > 50?\n",
    "                /         \\\n",
    "              Yes         No\n",
    "             /             \\\n",
    "        Is size > 30?   Is size > 10?\n",
    "          /     \\         /     \\\n",
    "       Galaxy  Star    Quasar   Star\n",
    "\n",
    "This method is useful for classification problems as it can be very quick to find an answer, depending on the dataset and the depth of your tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset as from a csv file to a Pandas dataframe\n",
    "path = '/Users/ryanu/Documents/Uni/ACT/SDSS-DR14-Classification/SDSS Data.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains 18 columns, however most of them are not needed. I have chosen to only use the five filter bands; u, g, r, i, and z as these are the physical parameters that are observed by the telescope. The rest are values assigned after the observations. I mention the redshift column later on in the redshift as this drastically changes the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = data[[\"u\", \"g\", \"r\", \"i\", \"z\"]]\n",
    "classification_examples = data[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be split into two parts. The training set will be used to train the model on how to classify the objects. The testing data is then used to determine how good the model is at classifying objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.901\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.91      0.92      0.91       996\n",
      "         QSO       0.87      0.85      0.86       190\n",
      "        STAR       0.89      0.89      0.89       814\n",
      "\n",
      "    accuracy                           0.90      2000\n",
      "   macro avg       0.89      0.89      0.89      2000\n",
      "weighted avg       0.90      0.90      0.90      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "training_param, testing_param, train_classification, testing_classification = train_test_split(parameters, classification_examples, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(training_param, train_classification)\n",
    "\n",
    "# Make predictions on the test set\n",
    "classification_predict = clf.predict(testing_param)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(testing_classification, classification_predict))\n",
    "print(\"Classification Report:\\n\", classification_report(testing_classification, classification_predict))\n",
    "\n",
    "\n",
    "# Plot the distribution of the classes with actual and correctly detected counts\n",
    "# Actual counts in the test set\n",
    "actual_counts = testing_classification.value_counts().sort_index()\n",
    "correct_counts = pd.Series(testing_classification[testing_classification == classification_predict]).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
