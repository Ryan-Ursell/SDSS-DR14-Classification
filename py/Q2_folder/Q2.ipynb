{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like in the Q1 notebook, we need to load the data in a useable form (i.e. a pandas dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path to where the csv file is stored on your pc\n",
    "path = '/Users/ryanu/Documents/Uni/ACT/SDSS-DR14-Classification/SDSS Data.csv'\n",
    "data = pd.read_csv(path)\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to start off using the same features as in Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['u', 'g', 'r', 'i', 'z']]\n",
    "labels = data['class']\n",
    "#features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels are encoded in alphabetical order as integers starting from 0 (e.g. Galaxy is 0, QSO is 1, Star is 2)\n",
    "    # This is because neural networks can only work with numerical data\n",
    "    # LabelEncoder() encodes the labels as integers\n",
    "    # fit_transform() is two steps in one: it calculates the mean and standard deviation, and then normalizes the data\n",
    "encoded_labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "# Features are normalized to have a mean of 0 and a standard deviation of 1\n",
    "    # This is important because neural networks tend to converge faster and perform better when the data is normalized.\n",
    "    # StandardScaler() initialises the data and prepares it for normalization\n",
    "    # fit_transform() is two steps in one: it calculates the mean and standard deviation, and then normalizes the data\n",
    "normalized_features = StandardScaler().fit_transform(features)\n",
    "\n",
    "# Convert features and labels into PyTorch tensors\n",
    "    # PyTorch tensors are similar to NumPy arrays, but they can be used on a GPU to accelerate computing\n",
    "    # torch.tensor() creates a tensor from a NumPy array\n",
    "    # dtype=torch.float32 and dtype=torch.long specify the data type of the tensor\n",
    "features_tensor = torch.tensor(normalized_features, dtype=torch.float32)\n",
    "labels_tensor = torch.tensor(encoded_labels, dtype=torch.long) # long is used for integers labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, verification, and testing sets\n",
    "    # train_test_split() splits the data into training and testing sets\n",
    "    # test_size=0.2 specifies that 20% of the data should be used for testing\n",
    "    # random_state=42 is a random seed used to shuffle the data\n",
    "    # The data is split into training and validation sets in a 80:20 ratio\n",
    "    # The training set is then split into training and validation sets in a 80:20 ratio\n",
    "    # The final data is split into training, validation, and testing sets in a 64:16:20 ratio\n",
    "features_train_val, features_test, label_train_val, label_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "features_train, features_val, label_train, label_val = train_test_split(features_train_val, label_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
